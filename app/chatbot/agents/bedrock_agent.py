#agents/bedrock_agent.py
from app.chatbot.chains.qa_chain import build_qa_chain
from app.chatbot.retrievers.kb_retriever import get_kb_retriever, get_llm
import re

# ê²€ìƒ‰ score ê¸°ì¤€ (ì´í•˜ì¼ ê²½ìš° ì‹¤íŒ¨ë¡œ ê°„ì£¼)
RELEVANCE_THRESHOLD = 0.5

def extract_best_time_and_text_with_ai(content: str, question: str, llm) -> str:
    """AIë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ìˆëŠ” ìë§‰ êµ¬ë¬¸ì„ ì„ íƒ"""
    pattern = r'\[at (\d+\.?\d*) seconds?\]\s*([^\n\r]+)'
    matches = re.findall(pattern, content)
    
    if not matches:
        return "ì‹œê°„ ì •ë³´ ì—†ìŒ"
    
    if len(matches) == 1:
        # í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        #123.45ì´ˆë¥¼ "2ë¶„ 3ì´ˆ" ì‹ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ë°”ê¾¸ëŠ” ê±°ì•¼
        # ì¦‰, ì‹œê°„ì„ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        sec, txt = matches[0]
        seconds = float(sec)
        minutes = int(seconds // 60)
        remaining_seconds = int(seconds % 60)
        if minutes > 0:
            time_str = f"{minutes}:{remaining_seconds:02d}"
        else:
            time_str = f"{remaining_seconds}ì´ˆ"
        return f"{time_str}: {txt.strip()}"
    
    # ì—¬ëŸ¬ ê°œê°€ ìˆìœ¼ë©´ AIë¡œ í‰ê°€
    try:
        # ê° êµ¬ë¬¸ì„ í‰ê°€í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        evaluation_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ìˆëŠ” ìë§‰ êµ¬ë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}

ìë§‰ êµ¬ë¬¸ë“¤:
"""
        for i, (sec, txt) in enumerate(matches, 1):
            evaluation_prompt += f"{i}. {txt.strip()}\n"
        
        evaluation_prompt += """
ìœ„ ìë§‰ êµ¬ë¬¸ë“¤ ì¤‘ì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ìˆëŠ” êµ¬ë¬¸ì˜ ë²ˆí˜¸ë§Œ ìˆ«ìë¡œ ë‹µí•´ì£¼ì„¸ìš”.
"""
        # AI í‰ê°€
        response = llm.invoke(evaluation_prompt)
        if hasattr(response, 'content'):
            result = response.content.strip()
        else:
            result = str(response).strip()
        
        # ìˆ«ì ì¶”ì¶œ
        # ì´ê±´ Claudeê°€ ì¤€ **"ë‹µë³€ ë¬¸ìì—´"**ì—ì„œ
        # ìˆ«ìë§Œ ë½‘ì•„ë‚´ì„œ â†’ ëª‡ ë²ˆì§¸ ë¬¸ì¥ì„ ì„ íƒí–ˆëŠ”ì§€ íŒŒì•…
        # ê·¸ ë‹¤ìŒì— í•´ë‹¹ matches[index]ë¥¼ ë‹¤ì‹œ êº¼ë‚´ì„œ ìœ„ì²˜ëŸ¼ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        number_match = re.search(r'\d+', result)
        if number_match:
            selected_idx = int(number_match.group()) - 1
            if 0 <= selected_idx < len(matches):
                sec, txt = matches[selected_idx]
                seconds = float(sec)
                minutes = int(seconds // 60)
                remaining_seconds = int(seconds % 60)
                if minutes > 0:
                    time_str = f"{minutes}:{remaining_seconds:02d}"
                else:
                    time_str = f"{remaining_seconds}ì´ˆ"
                return f"{time_str}: {txt.strip()}"
    
    except Exception as e:
        print(f"   - âš ï¸ AI í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # AI í‰ê°€ ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ êµ¬ë¬¸ ë°˜í™˜
    sec, txt = matches[0]
    seconds = float(sec)
    minutes = int(seconds // 60)
    remaining_seconds = int(seconds % 60)
    if minutes > 0:
        time_str = f"{minutes}:{remaining_seconds:02d}"
    else:
        time_str = f"{remaining_seconds}ì´ˆ"
    return f"{time_str}: {txt.strip()}"

def extract_video_id_from_content(content: str) -> str:
    """ìë§‰ ë‚´ìš©ì—ì„œ ë¹„ë””ì˜¤ IDë‚˜ íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„"""
    # íŒŒì¼ëª… íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: OA7LIkxp3_o_xxx.txt)
    video_pattern = r'([A-Za-z0-9_-]{11})_[a-f0-9]+\.txt'
    matches = re.findall(video_pattern, content)
    
    if matches:
        return f"YouTube ID: {matches[0]}"
    
    return "ë™ì˜ìƒ ì •ë³´ ì—†ìŒ"

def answer_question(question: str):
    retriever = get_kb_retriever()
    llm = get_llm()

    docs = retriever(question)

    # Bedrockì—ì„œ ë°˜í™˜í•œ score í™•ì¸
    high_quality_docs = [
        doc for doc in docs
        if doc.metadata.get("score", 1.0) >= RELEVANCE_THRESHOLD
    ]
    
    relevance_scores = [doc.metadata.get("score", 0.0) for doc in docs]

    if high_quality_docs:
        print("ğŸ“š âœ… KB ê²€ìƒ‰ ì„±ê³µ â†’ Claude + KB ì²´ì¸ ì‚¬ìš©")
        
        # ì¤‘ë³µ ì œê±°: ê°™ì€ ì‹œê°„ê³¼ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ ë¬¸ì„œëŠ” í•˜ë‚˜ë§Œ í‘œì‹œ
        unique_docs = []
        seen_content = set()
        
        for doc in high_quality_docs:
            time_and_text = extract_best_time_and_text_with_ai(doc.page_content, question, llm)
            if time_and_text not in seen_content:
                seen_content.add(time_and_text)
                unique_docs.append((doc, time_and_text))
        
        # ê³ ìœ í•œ ë¬¸ì„œë§Œ í‘œì‹œ
        for i, (doc, time_and_text) in enumerate(unique_docs, 1):
            print(f"   - ğŸ”— ë¬¸ì„œ {i}: {time_and_text}")
        
        # KB ê²€ìƒ‰ ê²°ê³¼ë¥¼ contextë¡œ ì‚¬ìš©
        context = "\n".join([doc.page_content for doc in high_quality_docs])
        qa_chain = build_qa_chain()
        response = qa_chain.invoke({"context": context, "question": question})
        
        # ì‘ë‹µì—ì„œ contentë§Œ ì¶”ì¶œ
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
            
        return {
            'answer': answer,
            'source_type': 'KB',
            'documents_found': len(high_quality_docs),
            'relevance_scores': relevance_scores[:5]  # ìƒìœ„ 5ê°œë§Œ
        }

    else:
        print("ğŸŒ â— KB ê²€ìƒ‰ ì‹¤íŒ¨ â†’ Claude ë‹¨ë… ì‘ë‹µ(Fallback)")
        response = llm.invoke(question)
        
        # ì‘ë‹µì—ì„œ contentë§Œ ì¶”ì¶œ
        if hasattr(response, 'content'):
            answer = response.content
        else:
            answer = str(response)
            
        return {
            'answer': answer,
            'source_type': 'FALLBACK',
            'documents_found': 0,
            'relevance_scores': relevance_scores[:5] if relevance_scores else []
        }